# Sensitivity Analysis II {#sensitivity2}

**Reference:**

- Peng and Tyler (2014), "Generalized Cornfield conditions for the risk difference"
- Peng and Tyler (2016), "Sensitivity Analysis Without Assumptions"
- Tyler and Peng (2017), "Sensitivity Analysis in Observational Research: Introducing the E-Value"

This chapter will cover the following topics:

- E-values
- Sensitivity analysis for IPW, OR and DR estimators.

A central question in causal inference with observational studies is the sensitivity of conclusions to unmeasured confounding.

First we introduce three variables to describe causal effect:

- Risk Difference = $$\tau = \mathbb{E}[Y_i(1) - Y_i(0)] = \mathbb{P}(Y_i(1)=1)-\mathbb{P}(Y_i(0)=1)$$
- Relative Risk (RR) = $$\frac{\mathbb{P}(Y_i(1)=1)}{\mathbb{P}(Y_i(0)=1)}$$ e.g. RR=3 means treatment causal increases the probability of $Y=1$ by a factor of 3
- Odds Ratio (OR) = $$\frac{\mathbb{P}(Y_i(1)=1)}{1-\mathbb{P}(Y_i(1)=1)}\bigg/\frac{\mathbb{P}(Y_i(0)=1)}{1-\mathbb{P}(Y_i(0)=1)}$$ e.g. OR=3 means treatment causal increases the odss of $Y=1$ by 3 fold.

**Goal:** we want to assess what happens to estimators of $tau$ and RR when an observed confounder $U$ is present

Review the assumptions:

- SUTUA: $Y_i = A_iY_i(1) + (1-A_i)Y_i(0)$
- Conditional ignorability: $Y_i(1),Y_i(0) \perp A_i |X_i$
- $0 << P(A_i=1|X_i=x) <<1 \,\,\forall x$

When $U$ is present, the assumptions becomes:

- Conditional ignorability: $Y_i(1),Y_i(0) \perp A_i |X_i, U_i$
- $0 << P(A_i=1|X_i=x, U_i=u) <<1 \,\,\forall x,u$

**Graphically:**

Let $RR_{AY}$ be the relative risk of treatment on outcome. Let $RR_{UA}$ be the relative risk of confounder on treatment. Let $RR_{UY}$ be the relative risk of confounder on outcome. In the presence of $U$, our estimators of $tau$ and RR are biased. We want to measure how much is this bias.

**Define:**
$$B =\frac{RR_{AU}RR_{UY}}{RR_{AU}+RR_{UY}-1}$$
**Theorem:**
$$RR_{AY} \geq \frac{\hat{RR}}{B}$$
Note that:

- This bound is sharp.
- $U$ can be any type (one dimension and multi-dimension).
- This formula can also be applied on the lower bound of the confidence interval.

Example: Study the causal effect of baby formula (A=1) on respiratory death (Y=1)

- $\hat{RR} = 3.9$, 95% CI:(1.8,8.7)
- They controlled for age, .... (Xs)

What if there is an $U$? How would this $U$ change the result?

$\exists U$ s.t. $RR_{UA} = 2$, probability of taking infants formula increase 2 and $RR_{UY} = 4$ If $U=1$, then baby is 4 times more likely to die than if $U=0$. Then 
$$RR_{AY} \geq \frac{3.9}{1.6} = 2.43$$ and $$L_{AY} \geq \frac{\hat{L}_{AY}}{B} = \frac{1.8}{1.6} = 1.125$$

## E-value

Suppose $RR_{UA} = RR_{UY}$, then $B = \frac{RR_{UA}^2}{2RR_{UA} -1}$. Then consider the point in the lower bound where $RR_{AY} = 1$,

$$1 = RR_{AY} \geq \frac{\hat{RR}}{B} = \frac{\hat{RR}}{\frac{RR_{AU}^2}{2RR_{AU} -1}}$$
Solve for $RR_{UA}$, we get the 
$$\text{E-value}=\hat{RR} + \sqrt{\hat{RR}(\hat{RR}-1)}$$
Note that:

- Higher E-value means the study is more robust to unmeasured U.
- E-calue is the minimum strength of assoication on the risk ratio scale, that an unmeasured confounder would need to have with both the treatment and outcome, conditional on the measured covariates, to explain away a treatment-outcome association.
- E-value is a continuous measure of an association's robustness to potential uncontrolled condounders. The lowerst possible E-value is 1 (that is, no unmeasured confounding is needed to explain away the observed association). The higher the E-value, the stronger the confounder associations must be to explain away the effect.i

**Risk difference $\tau$:** Let $\hat{\tau}$ be the estimator, Y binary, $p_1 = \mathbb{P}(Y_i = 1|A_i=1)$, $p_0 = \mathbb{P}(Y_i = 1|A_i=0)$ and $f = P(A_i=1)$.

**Theorem:**
$$\tau_{AY} \geq (p_1 - Bp_0)\sqrt{f + \frac{1-f}{B}}$$







 






