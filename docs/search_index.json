[
["index.html", "Causal Inference Chapter 1 Prerequisites", " Causal Inference Tuo Wang 2019-10-08 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],
["matching.html", "Chapter 2 Matching 2.1 Quick Review on Propensity Score 2.2 Multivariate Caliper Matching 2.3 Matching with Multiple controls", " Chapter 2 Matching This lecture note will cover the following topics: Multivariate Caliper Matching Matching with Multiple Controls 2.1 Quick Review on Propensity Score Propensity score is the conditional probability of exposure to treatment given the observed covariates, \\(e(\\mathbf{x}) = \\mathbb{Pr}(A = 1|\\mathbf{x})\\), where \\(\\mathbf{x}\\) is the covaraites and \\(A\\) is the intervention variable. The propensity score is unkown, but it can be estimated from the data. For example, we can use the logistic regression: \\[\\log\\{\\frac{e(\\mathbf{x_i})}{1 - e(\\mathbf{x_i})}\\} = \\beta_0 + \\mathbf{x_i}^T\\bf{\\beta}\\] 2.2 Multivariate Caliper Matching Why we need multivariate caliper matching? In lecture 6, we learned matching with propensity score, which tends to balance all of the covariates used to build that score, but two individuals with the same propensity score may differ in important ways. Also, propensity score matching is a single covariate matching, which ignore the interaction between different covarites. 2.2.1 (a) Mahalanobis Distances Let \\(\\mathbf{x}\\) be the covariates random vector. Let \\(\\hat{\\Sigma}\\) be the sample covariance matrix of \\(\\mathbf{x}\\). Then the estimated Mahalanobis distance between subject \\(i\\) and \\(j\\), who has covarates \\(\\mathbf{x_i}\\) and \\(\\mathbf{x_j}\\) repectively, is defined as: \\[d(\\mathbf{x_i}, \\mathbf{x_j}) = (\\mathbf{x_i} - \\mathbf{x_j})^T\\hat{\\Sigma}^{-1}(\\mathbf{x_i} - \\mathbf{x_j})\\] See the following comments on Mahalanobis distance from Rosenbaum’s book, Design of Observational Studies: “The Mahalanobis distance was originally developed for use with multivariate Nomal data, and for data of that type it works fine. With data that are not Normal, the Mahalanobis distance can exhibit some rather odd behavior. If one covariate contains extreme outliers of has a long-tailed distribution, its standard deviation will be inflated, and the Mahalanobis distance will tend to ignore that covariate in matching.” A simple alternative to the Mahalanobis distance is the ‘rank-based Mahalanobis distance’ which replaces each of the covariates by its ranks. Check out Design of Observational Studies, Chapter 8.3 for details. 2.2.2 (b) Penalize large distance The idea is that two individuals can be close on the propensity score to a degree, once this degree is achieved, covariates \\(\\mathbf{x}\\) may affect the distance. Define \\(w\\) as the caliper width. With \\(w\\), if two individuals have propensity scores that differ more than \\(w\\), we will add a penalty to the ahalanobis distance between subject \\(i\\) and \\(j\\). Explicitly, \\[ d_{new}(\\mathbf{x_i}, \\mathbf{x_j})= \\begin{cases} d(\\mathbf{x_i}, \\mathbf{x_j}) + p\\times \\big|\\text{logit}(e(\\mathbf{x_i}))-\\text{logit}(e(\\mathbf{x_j}))\\big|,&amp; \\text{if } \\big|\\text{logit}(e(\\mathbf{x_i}))-\\text{logit}(e(\\mathbf{x_j}))\\big| \\geq w\\\\ d(\\mathbf{x_i}, \\mathbf{x_j}), &amp; \\text{if } \\big|\\text{logit}(e(\\mathbf{x_i}))-\\text{logit}(e(\\mathbf{x_j}))\\big| &lt; w \\end{cases}\\] where \\(e(\\mathbf{x})\\) is the propensity score of covariates \\(\\mathbf{x}\\), \\(d(\\mathbf{x_i}, \\mathbf{x_j})\\) is the Mahalanobis distance between individual \\(i\\) and \\(j\\) and \\(p\\) is the penalty term. In practical, we may want to care about the following things: What’s the value of \\(p\\)? Usually \\(p = 1000\\). In Paul Rosenbaum’s 2019 review on matching: he used \\(d_{new}(\\mathbf{x_i}, \\mathbf{x_j}) = +\\infty\\) when \\(\\big|\\text{logit}(e(\\mathbf{x_i}))-\\text{logit}(e(\\mathbf{x_j}))\\big| \\geq w\\). What’s the value of \\(w\\)? People use \\(w = 0.5 \\times SD(\\text{logit}(e(\\mathbf{x})))\\) or \\(w = 0.2 \\times SD(\\text{logit}(e(\\mathbf{x})))\\) in practice. Comments: Use of the Mahalanobis distance inside propensity score calipers will balance covariates and also pair similar individuals. Also, using both Mahalanobis distance and propensity score calipers adds a protection against the failure of a single matching technique. 2.3 Matching with Multiple controls In previous matching algorithms, we only match one treatment with one control. In matching with multiple controls, each treatment is matched to at least one control. For example if we match 1 treatment with 2 controls, assume we have 10 subjects in treatment group, we will end up with 10 matched sets, which each contains 1 treatment and 2 controls. Note that the 20 controls included in matched sets need to be different. How many controls? Let \\(m\\) be the number of controls to be matched for one treatment. In Paul Rosenbaum’s 2019 review on matching: “Under a simple, familiar, conventional Gaussian model for matched sets, the variance of the estimator is proportional to 1+1/m, where the omitted constant of proportionality does not depend on m, but depends on all sorts of other things: the sample size, the variance of errors, and so on (see, for instance, Rosenbaum 2010, section 8.7)” For example, \\(m=1\\) means paired matching, then \\(1+\\frac{1}{m} = 2\\). If \\(m = +\\infty\\), then \\(1+\\frac{1}{m} = 1\\). Based on Rosenbaum’s comment, \\(1+\\frac{1}{m}\\) represents the variability. By adding controls from 1 to \\(+\\infty\\), the sampling uncertainty from controls reduces but the uncertainty from treatment is unchanged. For example when \\(m=10\\), \\(1+\\frac{1}{m} = 1.1\\) so almost all the uncertainty come from treatment group. In practice, \\(m = 3 \\sim 5\\). Pros and cons: Pros: Efficiency. More samples are included inside matched sets. Cons: Balance becomes terrible. "]
]
